{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据准备\n",
    "\n",
    "## 数据导入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-05T14:38:09.946080Z",
     "start_time": "2020-02-05T14:38:09.937279Z"
    },
    "code_folding": [
     4
    ]
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def load_data(path, add_time=True, describe=True):\n",
    "    data = pd.read_csv(path)\n",
    "    if describe:\n",
    "        display(data.describe())\n",
    "    if add_time:\n",
    "        data['Date'] = data['Date'].apply(lambda data: data.split('/'))\n",
    "        data['Year'] = data['Date'].apply(lambda data: int(data[2].split(' ')[0]))\n",
    "        data['Month'] = data['Date'].apply(lambda data: int(data[1]))\n",
    "        data['Day'] = data['Date'].apply(lambda data: int(data[0]))\n",
    "        data['Hour'] = data['Date'].apply(lambda data: int(data[2].split(' ')[1].split(':')[0]))\n",
    "        data.drop('Date', inplace=True, axis=1)\n",
    "        data = data[['Year', 'Month', 'Day','Hour','wind_speed', 'wind_direction', 'wind_power']]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-05T14:43:31.999061Z",
     "start_time": "2020-02-05T14:43:31.857478Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path = '/Users/apple/Documents/ML_Project/ML - 2.1/Data/国际西班牙数据.csv'\n",
    "data = load_data(path, add_time=True, describe=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "输出连续区间"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-05T14:31:07.567011Z",
     "start_time": "2020-02-05T14:31:07.515448Z"
    },
    "hide_input": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Continue: [ 0 , 975 ] len: 975 \tNan: [ 976 , 976 ] len: 1\n",
      "Continue: [ 977 , 2216 ] len: 1239 \tNan: [ 2217 , 2221 ] len: 5\n",
      "Continue: [ 2222 , 3498 ] len: 1276 \tNan: [ 3499 , 3560 ] len: 62\n",
      "Continue: [ 3561 , 3572 ] len: 11 \tNan: [ 3573 , 3589 ] len: 17\n",
      "Continue: [ 3590 , 4314 ] len: 724 \tNan: [ 4315 , 4401 ] len: 87\n",
      "Continue: [ 4402 , 6255 ] len: 1853 \tNan: [ 6256 , 6273 ] len: 18\n",
      "Continue: [ 6274 , 6375 ] len: 101 \tNan: [ 6376 , 6376 ] len: 1\n",
      "Continue: [ 6377 , 6417 ] len: 40 \tNan: [ 6418 , 6425 ] len: 8\n",
      "Continue: [ 6426 , 10427 ] len: 4001 \tNan: [ 10428 , 10447 ] len: 20\n",
      "Continue: [ 10448 , 13432 ] len: 2984 \tNan: [ 13433 , 13434 ] len: 2\n",
      "Continue: [ 13435 , 13976 ] len: 541 \tNan: [ 13977 , 13985 ] len: 9\n",
      "Continue: [ 13986 , 14000 ] len: 14 \tNan: [ 14001 , 14009 ] len: 9\n",
      "Continue: [ 14010 , 14024 ] len: 14 \tNan: [ 14025 , 14033 ] len: 9\n",
      "Continue: [ 14034 , 14048 ] len: 14 \tNan: [ 14049 , 14057 ] len: 9\n",
      "Continue: [ 14058 , 14072 ] len: 14 \tNan: [ 14073 , 14077 ] len: 5\n",
      "Continue: [ 14078 , 14387 ] len: 309 \tNan: [ 14388 , 14388 ] len: 1\n",
      "Continue: [ 14389 , 17872 ] len: 3483 \tNan: [ 17873 , 17887 ] len: 15\n",
      "Continue: [ 17888 , 18265 ] len: 377\n"
     ]
    }
   ],
   "source": [
    "index = data[data['wind_speed'].isna() |\n",
    "    data['wind_direction'].isna() |\n",
    "    data['wind_power'].isna()]['wind_power'].index.tolist()\n",
    "a = index[0]\n",
    "b=-1\n",
    "for i,x in enumerate(index):\n",
    "    if i<len(index)-1:\n",
    "        if index[i+1] > index[i]+1:\n",
    "            print('Continue: [',b+1, ',', a-1,']','len:',a-b-2,\n",
    "                '\\tNan: [',a, ',',index[i], '] len:',index[i]-a+1)     \n",
    "            a = index[i+1]\n",
    "            b = index[i]\n",
    "    else: \n",
    "        a=index[-15]\n",
    "        print('Continue: [',b+1, ',', a-1,']','len:',a-b-2,\n",
    "                '\\tNan: [',a, ',',index[i], '] len:',index[i]-a+1)     \n",
    "        a=len(data)\n",
    "        b=index[i]\n",
    "        print('Continue: [',b+1, ',', a-1,']','len:',a-b-2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-05T15:07:57.731284Z",
     "start_time": "2020-02-05T15:07:57.658917Z"
    },
    "code_folding": [
     3,
     36
    ]
   },
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_format='retina'\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "def plot_module1(year, month, day, data, figsize=(14,16), save_fig=False, close_fig=True):\n",
    "    data['ws_sin(wd)'] = data['wind_speed']*np.sin(data['wind_direction'])\n",
    "    data['ws_cos(wd)'] = data['wind_speed']*np.cos(data['wind_direction'])\n",
    "    data['ws_wd'] = data['wind_speed']*data['wind_direction']\n",
    "    data['ws(Scaled)_wd(Scaled)'] = \\\n",
    "    MinMaxScaler().fit_transform(data['wind_speed'].values.reshape(-1,1))*\\\n",
    "    MinMaxScaler().fit_transform(data['wind_direction'].values.reshape(-1,1))\n",
    "\n",
    "    data['wind_power(Scaled)'] = \\\n",
    "    MinMaxScaler().fit_transform(data['wind_power'].values.reshape(-1,1))\n",
    "    df = data\n",
    "    fig, axes = plt.subplots(4,2,figsize=figsize)\n",
    "    fig.suptitle('Year\\Month\\Day: {}\\{}\\{}'.format(year,month,day), fontsize=15)\n",
    "    df[(df['Year']==year) & (df['Month']==month) & (df['Day']==day)]['wind_speed'].plot(ax=axes[0,0],title='wind_speed', ylim=[0,7])\n",
    "    df[(df['Year']==year) & (df['Month']==month) & (df['Day']==day)]['wind_direction'].plot(ax=axes[1,0],title='wind_direction', ylim=[90,360])\n",
    "    df[(df['Year']==year) & (df['Month']==month) & (df['Day']==day)]['wind_power'].plot(ax=axes[2,0], title='wind_power', ylim=[0,5000])\n",
    "    df[(df['Year']==year) & (df['Month']==month) & (df['Day']==day)]['ws_sin(wd)'].plot(ax=axes[0,1],title='wind_speed*sin(wind_direction)')\n",
    "    df[(df['Year']==year) & (df['Month']==month) & (df['Day']==day)]['ws_cos(wd)'].plot(ax=axes[1,1],title='wind_speed * cos(wind_direction)')\n",
    "    df[(df['Year']==year) & (df['Month']==month) & (df['Day']==day)]['ws_wd'].plot(ax=axes[2,1],title='wind_speed*wind_direction')\n",
    "    # df[(df['Month']==month) & (df['Day']==day)]['ws(Scaled)_wd(Scaled)'].plot(ax=axes[3,1],title='wind_speed*wind_direction(Both Scaled)')\n",
    "\n",
    "\n",
    "    pd.Series(MinMaxScaler().fit_transform\\\n",
    "    (df[(df['Year']==year) & (df['Month']==month) & (df['Day']==day)]\\\n",
    "     ['wind_speed'].values.reshape(-1,1)).reshape(24,)).plot(ax=axes[3,0])\n",
    "\n",
    "    pd.Series(MinMaxScaler().fit_transform\\\n",
    "    (df[(df['Year']==year) & (df['Month']==month) & (df['Day']==day)]\\\n",
    "     ['wind_direction'].values.reshape(-1,1)).reshape(24,)).plot(ax=axes[3,0],title='wind_speed & wind_direction')\n",
    "    if save_fig:\n",
    "        plt.savefig('/Users/apple/Documents/ML_Project/ML - 2.1/figure/{}\\{}\\{}.png'.format(year,month,day))\n",
    "    if close_fig:\n",
    "        plt.close()\n",
    "def plot_module2(year, month, day, data, figsize=(14,14), save_fig=False, close_fig=True):\n",
    "    data['ws_sin(wd)'] = data['wind_speed']*np.sin(data['wind_direction'])\n",
    "    data['ws_cos(wd)'] = data['wind_speed']*np.cos(data['wind_direction'])\n",
    "    data['ws_wd'] = data['wind_speed']*data['wind_direction']\n",
    "    data['ws(Scaled)_wd(Scaled)'] = \\\n",
    "    MinMaxScaler().fit_transform(data['wind_speed'].values.reshape(-1,1))*\\\n",
    "    MinMaxScaler().fit_transform(data['wind_direction'].values.reshape(-1,1))\n",
    "\n",
    "    data['wind_power(Scaled)'] = \\\n",
    "    MinMaxScaler().fit_transform(data['wind_power'].values.reshape(-1,1))\n",
    "    df = data\n",
    "    fig, axes = plt.subplots(3,2,figsize=figsize)\n",
    "    fig.suptitle('Year\\Month\\Day: {}\\{}\\{}'.format(year,month,day), fontsize=15)\n",
    "    df[(df['Year']==year) & (df['Month']==month) & (df['Day']==day)]['wind_speed'].plot(ax=axes[0,0],title='wind_speed', ylim=[0,7])\n",
    "    df[(df['Year']==year) & (df['Month']==month) & (df['Day']==day)]['wind_direction'].plot(ax=axes[1,0],title='wind_direction', ylim=[90,360])\n",
    "    df[(df['Year']==year) & (df['Month']==month) & (df['Day']==day)]['wind_power'].plot(ax=axes[2,0], title='wind_power', ylim=[0,5000])\n",
    "    df[(df['Year']==year) & (df['Month']==month) & (df['Day']==day)]['wind_power(Scaled)'].plot(ax=axes[1,1],title='wind_power(Scaled)')\n",
    "    df[(df['Year']==year) & (df['Month']==month) & (df['Day']==day)]['ws_wd'].plot(ax=axes[2,1],title='wind_speed * wind_direction')\n",
    "    \n",
    "    pd.Series(MinMaxScaler().fit_transform\\\n",
    "              (df[(df['Year']==year) & (df['Month']==month) & (df['Day']==day)]\\\n",
    "               ['wind_speed'].values.reshape(-1,1)).reshape(24,)).plot(ax=axes[0,1])\n",
    "\n",
    "    pd.Series(MinMaxScaler().fit_transform\\\n",
    "              (df[(df['Year']==year) & (df['Month']==month) & (df['Day']==day)]\\\n",
    "               ['wind_direction'].values.reshape(-1,1)).reshape(24,)).plot(ax=axes[0,1],title='wind_speed(Scaled) & wind_direction(Scaled)')\n",
    "    if save_fig:\n",
    "        plt.savefig('/Users/apple/Documents/ML_Project/ML - 2.1/figure/{}\\{}\\{}.png'.format(year,month,day))\n",
    "    if close_fig:\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-05T15:10:15.326449Z",
     "start_time": "2020-02-05T15:10:14.792009Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ae3b9f65a3b424d9e42153ab093cc50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5be059b8fb7c42e5acd4bc1264d6a4dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm as tqdm\n",
    "for day in tqdm(np.arange(1,2)):\n",
    "    plot_module1(year=2017, month=10, day=day, data=data, \n",
    "                 figsize=(8,13), save_fig=False, close_fig=True)\n",
    "for day in tqdm(np.arange(1,2)):\n",
    "    plot_module2(year=2017, month=10, day=day, data=data, \n",
    "                 figsize=(8,10), save_fig=False, close_fig=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据扩增"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-05T14:37:01.429339Z",
     "start_time": "2020-02-05T14:37:01.422135Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def Data_Extend_fun(Data, hour_num, columns):\n",
    "    if hour_num==0:\n",
    "        return Data\n",
    "    elif hour_num>0:\n",
    "        Extend_data = Data[hour_num:len(Data)].copy()\n",
    "        Extend_data.index = np.arange(0,len(Extend_data)).tolist()\n",
    "        for index in columns:\n",
    "            for i in np.arange(1,hour_num+1):\n",
    "                a = Data[index].iloc[(hour_num-i):-i].copy()\n",
    "                a.index = np.arange(0,len(Extend_data)).tolist()\n",
    "                Extend_data[index+'-{}'.format(i)] = a\n",
    "        return Extend_data\n",
    "    else:\n",
    "        print('ERROR: hour num cannot be negative!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-05T14:41:59.894423Z",
     "start_time": "2020-02-05T14:41:59.879177Z"
    },
    "code_folding": [
     1
    ]
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "def get_data(Data, \n",
    "             hour_num=0, \n",
    "             columns=['wind_speed', 'wind_direction', 'wind_power'], \n",
    "             train_index=[6426,10427],\n",
    "             test_index=[14389,17872],\n",
    "             drop_time=True,\n",
    "             scale=True):\n",
    "    Train = Data_Extend_fun(Data=data.iloc[train_index[0]:train_index[1]],\n",
    "                            hour_num=hour_num,columns = columns)\n",
    "    Test = Data_Extend_fun(Data=data.iloc[test_index[0]:test_index[1]],\n",
    "                           hour_num=hour_num,columns = columns)\n",
    "\n",
    "    X_train = Train.drop('wind_power', axis=1)\n",
    "    X_test = Test.drop('wind_power', axis=1)\n",
    "    Y_train = Train['wind_power']\n",
    "    Y_test = Test['wind_power']\n",
    "\n",
    "    if drop_time:\n",
    "        X_train.drop(['Year', 'Month', 'Day','Hour'], axis=1)\n",
    "        X_test.drop(['Year', 'Month', 'Day','Hour'], axis=1)\n",
    "        \n",
    "    if scale:\n",
    "        X_Scaler = MinMaxScaler()\n",
    "        X_train = X_Scaler.fit_transform(X_train)\n",
    "        X_test = X_Scaler.transform(X_test)\n",
    "\n",
    "        Y_Scaler = MinMaxScaler()\n",
    "        Y_train = Y_Scaler.fit_transform(Y_train.values.reshape(-1,1)).reshape(len(Y_train),)\n",
    "        Y_test = Y_Scaler.transform(Y_test.values.reshape(-1,1)).reshape(len(Y_test),)\n",
    "    return X_train, X_test, Y_train, Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-05T14:52:48.462971Z",
     "start_time": "2020-02-05T14:52:48.446211Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = get_data(data, hour_num=3, \n",
    "                                            drop_time=True,scale=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "不扩增优于扩增"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-05T14:38:21.404152Z",
     "start_time": "2020-02-05T14:38:21.397253Z"
    },
    "code_folding": [
     2
    ]
   },
   "outputs": [],
   "source": [
    "from ngboost import NGBRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "def model_test(Base, X_train, X_test, Y_train, Y_test, \n",
    "               n_estimators=500, verbose_eval=100):\n",
    "    ngb = NGBRegressor(Base=Base, \n",
    "                       n_estimators=n_estimators,\n",
    "                       verbose_eval=verbose_eval)\n",
    "    print(ngb,'\\n')\n",
    "    ngb.fit(X_train, Y_train)\n",
    "\n",
    "    Y_preds = ngb.predict(X_test)\n",
    "    Y_dists = ngb.pred_dist(X_test) # return norm method: mean std\n",
    "\n",
    "    # test Mean Squared Error\n",
    "    test_MSE = mean_squared_error(Y_preds, Y_test)\n",
    "    print('\\nTest MSE', test_MSE)\n",
    "\n",
    "    # test Negative Log Likelihood\n",
    "    test_NLL = -Y_dists.logpdf(Y_test).mean()\n",
    "    print('Test NLL', test_NLL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. linear_svr_learner（0.0245）\n",
    "2. esn_linear_svr_learner（0.0275）\n",
    "3. default_linear_learner（0.0312）\n",
    "4. default_tree_learner（0.0425）\n",
    "5. esn_kernel_ridge_learner（0.0442）\n",
    "6. kernel_ridge_learner（0.0478）\n",
    "7. esn_ridge_learner（0.0482）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## default_linear_learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-05T14:44:10.258408Z",
     "start_time": "2020-02-05T14:44:02.802031Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NGBRegressor(Base=Ridge(alpha=0.1, copy_X=True, fit_intercept=True,\n",
      "                        max_iter=None, normalize=False, random_state=None,\n",
      "                        solver='auto', tol=0.001),\n",
      "             Dist=<class 'ngboost.distns.normal.Normal'>,\n",
      "             Score=<class 'ngboost.scores.MLE'>, learning_rate=0.01,\n",
      "             minibatch_frac=1.0, n_estimators=500, natural_gradient=True,\n",
      "             tol=0.0001, verbose=True, verbose_eval=100) \n",
      "\n",
      "[iter 0] loss=0.0536 val_loss=0.0000 scale=0.5000 norm=0.2703\n",
      "[iter 100] loss=-0.3436 val_loss=0.0000 scale=0.1250 norm=0.0571\n",
      "[iter 200] loss=-0.3690 val_loss=0.0000 scale=0.0312 norm=0.0139\n",
      "[iter 300] loss=-0.3706 val_loss=0.0000 scale=0.0078 norm=0.0034\n",
      "[iter 400] loss=-0.3707 val_loss=0.0000 scale=0.0020 norm=0.0009\n",
      "\n",
      "Test MSE 0.031239293219421656\n",
      "Test NLL -0.3310202514535008\n"
     ]
    }
   ],
   "source": [
    "from ngboost.learners import default_linear_learner\n",
    "model_test(Base=default_linear_learner(alpha=0.1),\n",
    "           X_train=X_train, X_test=X_test,\n",
    "           Y_train=Y_train, Y_test=Y_test,\n",
    "          n_estimators=500, verbose_eval=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## default_tree_learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-05T13:47:04.991762Z",
     "start_time": "2020-02-05T13:45:37.298952Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NGBRegressor(Base=DecisionTreeRegressor(criterion='friedman_mse', max_depth=6,\n",
      "                                        max_features=None, max_leaf_nodes=None,\n",
      "                                        min_impurity_decrease=0.0,\n",
      "                                        min_impurity_split=None,\n",
      "                                        min_samples_leaf=1, min_samples_split=2,\n",
      "                                        min_weight_fraction_leaf=0.0,\n",
      "                                        presort=False, random_state=None,\n",
      "                                        splitter='best'),\n",
      "             Dist=<class 'ngboost.distns.normal.Normal'>,\n",
      "             Score=<class 'ngboost.scores.MLE'>, learning_rate=0.01,\n",
      "             minibatch_frac=1.0, n_estimators=1000, natural_gradient=True,\n",
      "             tol=0.0001, verbose=True, verbose_eval=200) \n",
      "\n",
      "[iter 0] loss=0.0537 val_loss=0.0000 scale=0.5000 norm=0.2702\n",
      "[iter 200] loss=-0.3028 val_loss=0.0000 scale=0.1250 norm=0.0480\n",
      "[iter 400] loss=-0.3134 val_loss=0.0000 scale=0.0156 norm=0.0058\n",
      "[iter 600] loss=-0.3138 val_loss=0.0000 scale=0.0039 norm=0.0015\n",
      "[iter 800] loss=-0.3138 val_loss=0.0000 scale=0.0010 norm=0.0004\n",
      "\n",
      "Test MSE 0.04250915281935243\n",
      "Test NLL -0.2297540065127703\n"
     ]
    }
   ],
   "source": [
    "from ngboost.learners import default_tree_learner\n",
    "model_test(Base=default_tree_learner(depth=6),\n",
    "           X_train=X_train, X_test=X_test,\n",
    "           Y_train=Y_train, Y_test=Y_test,\n",
    "          n_estimators=1000, verbose_eval=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## linear_svr_learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-05T13:44:17.211233Z",
     "start_time": "2020-02-05T13:43:53.726395Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NGBRegressor(Base=LinearSVR(C=0.05, dual=True, epsilon=0.0, fit_intercept=True,\n",
      "                            intercept_scaling=1.0, loss='epsilon_insensitive',\n",
      "                            max_iter=1000, random_state=None, tol=0.0001,\n",
      "                            verbose=0),\n",
      "             Dist=<class 'ngboost.distns.normal.Normal'>,\n",
      "             Score=<class 'ngboost.scores.MLE'>, learning_rate=0.01,\n",
      "             minibatch_frac=1.0, n_estimators=500, natural_gradient=True,\n",
      "             tol=0.0001, verbose=True, verbose_eval=100) \n",
      "\n",
      "[iter 0] loss=0.0537 val_loss=0.0000 scale=1.0000 norm=0.5405\n",
      "[iter 100] loss=-0.2473 val_loss=0.0000 scale=0.2500 norm=0.1247\n",
      "[iter 200] loss=-0.2932 val_loss=0.0000 scale=0.0625 norm=0.0300\n",
      "[iter 300] loss=-0.2994 val_loss=0.0000 scale=0.0156 norm=0.0072\n",
      "[iter 400] loss=-0.2999 val_loss=0.0000 scale=0.0078 norm=0.0036\n",
      "\n",
      "Test MSE 0.024508858474129803\n",
      "Test NLL -0.3773893376173749\n"
     ]
    }
   ],
   "source": [
    "from ngboost.learners import linear_svr_learner\n",
    "model_test(Base=linear_svr_learner(epsilon=0.0, \n",
    "                                   C=0.05, \n",
    "                                   max_iter=10000),\n",
    "           X_train=X_train, X_test=X_test,\n",
    "           Y_train=Y_train, Y_test=Y_test,\n",
    "          n_estimators=500, verbose_eval=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## kernel_ridge_learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-05T08:40:31.197589Z",
     "start_time": "2020-02-05T07:51:40.981604Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NGBRegressor(Base=KernelRidge(alpha=0.5, coef0=1, degree=3, gamma=None,\n",
      "                              kernel='poly', kernel_params=None),\n",
      "             Dist=<class 'ngboost.distns.normal.Normal'>,\n",
      "             Score=<class 'ngboost.scores.MLE'>, learning_rate=0.01,\n",
      "             minibatch_frac=1.0, n_estimators=500, natural_gradient=True,\n",
      "             tol=0.0001, verbose=True, verbose_eval=10) \n",
      "\n",
      "[iter 0] loss=0.0537 val_loss=0.0000 scale=1.0000 norm=0.5405\n",
      "[iter 10] loss=-0.0879 val_loss=0.0000 scale=0.5000 norm=0.2335\n",
      "[iter 20] loss=-0.1340 val_loss=0.0000 scale=0.5000 norm=0.2299\n",
      "[iter 30] loss=-0.1735 val_loss=0.0000 scale=0.5000 norm=0.2303\n",
      "[iter 40] loss=-0.2086 val_loss=0.0000 scale=0.5000 norm=0.2329\n",
      "[iter 50] loss=-0.2354 val_loss=0.0000 scale=0.2500 norm=0.1180\n",
      "[iter 60] loss=-0.2499 val_loss=0.0000 scale=0.2500 norm=0.1189\n",
      "[iter 70] loss=-0.2633 val_loss=0.0000 scale=0.2500 norm=0.1198\n",
      "[iter 80] loss=-0.2756 val_loss=0.0000 scale=0.2500 norm=0.1206\n",
      "[iter 90] loss=-0.2865 val_loss=0.0000 scale=0.2500 norm=0.1213\n",
      "[iter 100] loss=-0.2938 val_loss=0.0000 scale=0.1250 norm=0.0609\n",
      "[iter 110] loss=-0.2982 val_loss=0.0000 scale=0.1250 norm=0.0610\n",
      "[iter 120] loss=-0.3021 val_loss=0.0000 scale=0.1250 norm=0.0610\n",
      "[iter 130] loss=-0.3056 val_loss=0.0000 scale=0.1250 norm=0.0611\n",
      "[iter 140] loss=-0.3087 val_loss=0.0000 scale=0.1250 norm=0.0611\n",
      "[iter 150] loss=-0.3111 val_loss=0.0000 scale=0.0625 norm=0.0305\n",
      "[iter 160] loss=-0.3123 val_loss=0.0000 scale=0.0625 norm=0.0305\n",
      "[iter 170] loss=-0.3134 val_loss=0.0000 scale=0.0625 norm=0.0305\n",
      "[iter 180] loss=-0.3143 val_loss=0.0000 scale=0.0625 norm=0.0305\n",
      "[iter 190] loss=-0.3151 val_loss=0.0000 scale=0.0625 norm=0.0304\n",
      "[iter 200] loss=-0.3158 val_loss=0.0000 scale=0.0625 norm=0.0304\n",
      "[iter 210] loss=-0.3162 val_loss=0.0000 scale=0.0312 norm=0.0152\n",
      "[iter 220] loss=-0.3165 val_loss=0.0000 scale=0.0312 norm=0.0152\n",
      "[iter 230] loss=-0.3167 val_loss=0.0000 scale=0.0312 norm=0.0152\n",
      "[iter 240] loss=-0.3169 val_loss=0.0000 scale=0.0312 norm=0.0152\n",
      "[iter 250] loss=-0.3171 val_loss=0.0000 scale=0.0312 norm=0.0152\n",
      "[iter 260] loss=-0.3172 val_loss=0.0000 scale=0.0156 norm=0.0076\n",
      "[iter 270] loss=-0.3173 val_loss=0.0000 scale=0.0156 norm=0.0076\n",
      "[iter 280] loss=-0.3173 val_loss=0.0000 scale=0.0156 norm=0.0076\n",
      "[iter 290] loss=-0.3174 val_loss=0.0000 scale=0.0156 norm=0.0076\n",
      "[iter 300] loss=-0.3174 val_loss=0.0000 scale=0.0156 norm=0.0076\n",
      "[iter 310] loss=-0.3175 val_loss=0.0000 scale=0.0078 norm=0.0038\n",
      "[iter 320] loss=-0.3175 val_loss=0.0000 scale=0.0078 norm=0.0038\n",
      "[iter 330] loss=-0.3175 val_loss=0.0000 scale=0.0078 norm=0.0038\n",
      "[iter 340] loss=-0.3175 val_loss=0.0000 scale=0.0078 norm=0.0038\n",
      "[iter 350] loss=-0.3175 val_loss=0.0000 scale=0.0078 norm=0.0038\n",
      "[iter 360] loss=-0.3175 val_loss=0.0000 scale=0.0039 norm=0.0019\n",
      "[iter 370] loss=-0.3175 val_loss=0.0000 scale=0.0039 norm=0.0019\n",
      "[iter 380] loss=-0.3175 val_loss=0.0000 scale=0.0039 norm=0.0019\n",
      "[iter 390] loss=-0.3175 val_loss=0.0000 scale=0.0039 norm=0.0019\n",
      "[iter 400] loss=-0.3175 val_loss=0.0000 scale=0.0039 norm=0.0019\n",
      "[iter 410] loss=-0.3176 val_loss=0.0000 scale=0.0020 norm=0.0009\n",
      "[iter 420] loss=-0.3176 val_loss=0.0000 scale=0.0020 norm=0.0009\n",
      "[iter 430] loss=-0.3176 val_loss=0.0000 scale=0.0020 norm=0.0009\n",
      "[iter 440] loss=-0.3176 val_loss=0.0000 scale=0.0020 norm=0.0009\n",
      "[iter 450] loss=-0.3176 val_loss=0.0000 scale=0.0020 norm=0.0009\n",
      "[iter 460] loss=-0.3176 val_loss=0.0000 scale=0.0010 norm=0.0005\n",
      "[iter 470] loss=-0.3176 val_loss=0.0000 scale=0.0010 norm=0.0005\n",
      "[iter 480] loss=-0.3176 val_loss=0.0000 scale=0.0010 norm=0.0005\n",
      "[iter 490] loss=-0.3176 val_loss=0.0000 scale=0.0010 norm=0.0005\n",
      "\n",
      "Test MSE 0.04785360045512386\n",
      "Test NLL -0.18652255864231546\n"
     ]
    }
   ],
   "source": [
    "from ngboost.learners import kernel_ridge_learner\n",
    "model_test(Base=kernel_ridge_learner(alpha=0.5, \n",
    "                                    kernel=\"poly\",\n",
    "                                    degree=3),\n",
    "           X_train=X_train, X_test=X_test,\n",
    "           Y_train=Y_train, Y_test=Y_test,\n",
    "          n_estimators=500, verbose_eval=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## esn_ridge_learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-03T08:56:08.762282Z",
     "start_time": "2020-02-03T08:45:54.167662Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NGBRegressor(Base=<function esn_ridge_learner at 0x1a191217b8>,\n",
      "             Dist=<class 'ngboost.distns.normal.Normal'>,\n",
      "             Score=<class 'ngboost.scores.MLE'>, learning_rate=0.01,\n",
      "             minibatch_frac=1.0, n_estimators=500, natural_gradient=True,\n",
      "             tol=0.0001, verbose=True, verbose_eval=10) \n",
      "\n",
      "[iter 0] loss=0.0535 val_loss=0.0000 scale=1.0000 norm=0.5407\n",
      "[iter 10] loss=-0.0623 val_loss=0.0000 scale=1.0000 norm=0.4658\n",
      "[iter 20] loss=-0.1406 val_loss=0.0000 scale=1.0000 norm=0.4331\n",
      "[iter 30] loss=-0.2038 val_loss=0.0000 scale=1.0000 norm=0.4176\n",
      "[iter 40] loss=-0.2585 val_loss=0.0000 scale=1.0000 norm=0.4105\n",
      "[iter 50] loss=-0.3082 val_loss=0.0000 scale=1.0000 norm=0.4077\n",
      "[iter 60] loss=-0.3543 val_loss=0.0000 scale=1.0000 norm=0.4072\n",
      "[iter 70] loss=-0.3978 val_loss=0.0000 scale=1.0000 norm=0.4078\n",
      "[iter 80] loss=-0.4392 val_loss=0.0000 scale=1.0000 norm=0.4090\n",
      "[iter 90] loss=-0.4788 val_loss=0.0000 scale=1.0000 norm=0.4102\n",
      "[iter 100] loss=-0.5170 val_loss=0.0000 scale=1.0000 norm=0.4114\n",
      "[iter 110] loss=-0.5538 val_loss=0.0000 scale=1.0000 norm=0.4123\n",
      "[iter 120] loss=-0.5891 val_loss=0.0000 scale=1.0000 norm=0.4130\n",
      "[iter 130] loss=-0.6231 val_loss=0.0000 scale=1.0000 norm=0.4133\n",
      "[iter 140] loss=-0.6558 val_loss=0.0000 scale=1.0000 norm=0.4132\n",
      "[iter 150] loss=-0.6873 val_loss=0.0000 scale=1.0000 norm=0.4128\n",
      "[iter 160] loss=-0.7174 val_loss=0.0000 scale=1.0000 norm=0.4121\n",
      "[iter 170] loss=-0.7462 val_loss=0.0000 scale=1.0000 norm=0.4111\n",
      "[iter 180] loss=-0.7739 val_loss=0.0000 scale=1.0000 norm=0.4098\n",
      "[iter 190] loss=-0.8002 val_loss=0.0000 scale=1.0000 norm=0.4085\n",
      "[iter 200] loss=-0.8251 val_loss=0.0000 scale=1.0000 norm=0.4069\n",
      "[iter 210] loss=-0.8491 val_loss=0.0000 scale=1.0000 norm=0.4053\n",
      "[iter 220] loss=-0.8715 val_loss=0.0000 scale=1.0000 norm=0.4036\n",
      "[iter 230] loss=-0.8928 val_loss=0.0000 scale=1.0000 norm=0.4020\n",
      "[iter 240] loss=-0.9131 val_loss=0.0000 scale=1.0000 norm=0.4007\n",
      "[iter 250] loss=-0.9320 val_loss=0.0000 scale=1.0000 norm=0.3994\n",
      "[iter 260] loss=-0.9497 val_loss=0.0000 scale=1.0000 norm=0.3983\n",
      "[iter 270] loss=-0.9662 val_loss=0.0000 scale=1.0000 norm=0.3976\n",
      "[iter 280] loss=-0.9819 val_loss=0.0000 scale=1.0000 norm=0.3973\n",
      "[iter 290] loss=-0.9964 val_loss=0.0000 scale=1.0000 norm=0.3973\n",
      "[iter 300] loss=-1.0098 val_loss=0.0000 scale=1.0000 norm=0.3976\n",
      "[iter 310] loss=-1.0224 val_loss=0.0000 scale=1.0000 norm=0.3982\n",
      "[iter 320] loss=-1.0340 val_loss=0.0000 scale=1.0000 norm=0.3990\n",
      "[iter 330] loss=-1.0449 val_loss=0.0000 scale=1.0000 norm=0.4001\n",
      "[iter 340] loss=-1.0547 val_loss=0.0000 scale=1.0000 norm=0.4014\n",
      "[iter 350] loss=-1.0639 val_loss=0.0000 scale=1.0000 norm=0.4030\n",
      "[iter 360] loss=-1.0724 val_loss=0.0000 scale=1.0000 norm=0.4047\n",
      "[iter 370] loss=-1.0803 val_loss=0.0000 scale=1.0000 norm=0.4066\n",
      "[iter 380] loss=-1.0877 val_loss=0.0000 scale=1.0000 norm=0.4086\n",
      "[iter 390] loss=-1.0947 val_loss=0.0000 scale=1.0000 norm=0.4105\n",
      "[iter 400] loss=-1.1006 val_loss=0.0000 scale=1.0000 norm=0.4127\n",
      "[iter 410] loss=-1.1064 val_loss=0.0000 scale=1.0000 norm=0.4147\n",
      "[iter 420] loss=-1.1120 val_loss=0.0000 scale=1.0000 norm=0.4167\n",
      "[iter 430] loss=-1.1170 val_loss=0.0000 scale=1.0000 norm=0.4187\n",
      "[iter 440] loss=-1.1218 val_loss=0.0000 scale=1.0000 norm=0.4208\n",
      "[iter 450] loss=-1.1265 val_loss=0.0000 scale=1.0000 norm=0.4227\n",
      "[iter 460] loss=-1.1308 val_loss=0.0000 scale=1.0000 norm=0.4246\n",
      "[iter 470] loss=-1.1347 val_loss=0.0000 scale=1.0000 norm=0.4266\n",
      "[iter 480] loss=-1.1381 val_loss=0.0000 scale=1.0000 norm=0.4287\n",
      "[iter 490] loss=-1.1417 val_loss=0.0000 scale=1.0000 norm=0.4305\n",
      "\n",
      "Test MSE 0.04821241184348232\n",
      "Test NLL 4.809396096838933\n"
     ]
    }
   ],
   "source": [
    "from ngboost.learners import esn_ridge_learner\n",
    "model_test(Base=esn_ridge_learner(n_readout=1000,\n",
    "                                  n_components=100,\n",
    "                                  alpha=0.01),\n",
    "           X_train=X_train, X_test=X_test,\n",
    "           Y_train=Y_train, Y_test=Y_test,\n",
    "          n_estimators=500, verbose_eval=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## esn_kernel_ridge_learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-05T09:38:22.570817Z",
     "start_time": "2020-02-05T08:40:31.236101Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NGBRegressor(Base=<ngboost.esn_learners.ESN_kernel_ridge_learner object at 0x1a1e7d39e8>,\n",
      "             Dist=<class 'ngboost.distns.normal.Normal'>,\n",
      "             Score=<class 'ngboost.scores.MLE'>, learning_rate=0.01,\n",
      "             minibatch_frac=1.0, n_estimators=500, natural_gradient=True,\n",
      "             tol=0.0001, verbose=True, verbose_eval=5) \n",
      "\n",
      "[iter 0] loss=0.0537 val_loss=0.0000 scale=1.0000 norm=0.5405\n",
      "[iter 5] loss=-0.0293 val_loss=0.0000 scale=1.0000 norm=0.4918\n",
      "[iter 10] loss=-0.0767 val_loss=0.0000 scale=0.5000 norm=0.2369\n",
      "[iter 15] loss=-0.1013 val_loss=0.0000 scale=0.5000 norm=0.2340\n",
      "[iter 20] loss=-0.1238 val_loss=0.0000 scale=0.5000 norm=0.2325\n",
      "[iter 25] loss=-0.1447 val_loss=0.0000 scale=0.5000 norm=0.2320\n",
      "[iter 30] loss=-0.1642 val_loss=0.0000 scale=0.5000 norm=0.2322\n",
      "[iter 35] loss=-0.1826 val_loss=0.0000 scale=0.5000 norm=0.2331\n",
      "[iter 40] loss=-0.1999 val_loss=0.0000 scale=0.5000 norm=0.2344\n",
      "[iter 45] loss=-0.2163 val_loss=0.0000 scale=0.5000 norm=0.2360\n",
      "[iter 50] loss=-0.2301 val_loss=0.0000 scale=0.2500 norm=0.1188\n",
      "[iter 55] loss=-0.2375 val_loss=0.0000 scale=0.2500 norm=0.1192\n",
      "[iter 60] loss=-0.2446 val_loss=0.0000 scale=0.2500 norm=0.1197\n",
      "[iter 65] loss=-0.2515 val_loss=0.0000 scale=0.2500 norm=0.1201\n",
      "[iter 70] loss=-0.2581 val_loss=0.0000 scale=0.2500 norm=0.1206\n",
      "[iter 75] loss=-0.2643 val_loss=0.0000 scale=0.2500 norm=0.1210\n",
      "[iter 80] loss=-0.2703 val_loss=0.0000 scale=0.2500 norm=0.1214\n",
      "[iter 85] loss=-0.2759 val_loss=0.0000 scale=0.2500 norm=0.1218\n",
      "[iter 90] loss=-0.2813 val_loss=0.0000 scale=0.2500 norm=0.1221\n",
      "[iter 95] loss=-0.2863 val_loss=0.0000 scale=0.2500 norm=0.1224\n",
      "[iter 100] loss=-0.2900 val_loss=0.0000 scale=0.1250 norm=0.0613\n",
      "[iter 105] loss=-0.2922 val_loss=0.0000 scale=0.1250 norm=0.0613\n",
      "[iter 110] loss=-0.2943 val_loss=0.0000 scale=0.1250 norm=0.0614\n",
      "[iter 115] loss=-0.2963 val_loss=0.0000 scale=0.1250 norm=0.0614\n",
      "[iter 120] loss=-0.2982 val_loss=0.0000 scale=0.1250 norm=0.0615\n",
      "[iter 125] loss=-0.3000 val_loss=0.0000 scale=0.1250 norm=0.0615\n",
      "[iter 130] loss=-0.3017 val_loss=0.0000 scale=0.1250 norm=0.0615\n",
      "[iter 135] loss=-0.3033 val_loss=0.0000 scale=0.1250 norm=0.0615\n",
      "[iter 140] loss=-0.3048 val_loss=0.0000 scale=0.1250 norm=0.0615\n",
      "[iter 145] loss=-0.3062 val_loss=0.0000 scale=0.1250 norm=0.0615\n",
      "[iter 150] loss=-0.3073 val_loss=0.0000 scale=0.1250 norm=0.0615\n",
      "[iter 155] loss=-0.3081 val_loss=0.0000 scale=0.0625 norm=0.0307\n",
      "[iter 160] loss=-0.3087 val_loss=0.0000 scale=0.0625 norm=0.0307\n",
      "[iter 165] loss=-0.3092 val_loss=0.0000 scale=0.0625 norm=0.0307\n",
      "[iter 170] loss=-0.3097 val_loss=0.0000 scale=0.0625 norm=0.0307\n",
      "[iter 175] loss=-0.3102 val_loss=0.0000 scale=0.0625 norm=0.0307\n",
      "[iter 180] loss=-0.3106 val_loss=0.0000 scale=0.0625 norm=0.0307\n",
      "[iter 185] loss=-0.3111 val_loss=0.0000 scale=0.0625 norm=0.0307\n",
      "[iter 190] loss=-0.3114 val_loss=0.0000 scale=0.0625 norm=0.0307\n",
      "[iter 195] loss=-0.3118 val_loss=0.0000 scale=0.0625 norm=0.0307\n",
      "[iter 200] loss=-0.3121 val_loss=0.0000 scale=0.0625 norm=0.0307\n",
      "[iter 205] loss=-0.3123 val_loss=0.0000 scale=0.0312 norm=0.0153\n",
      "[iter 210] loss=-0.3125 val_loss=0.0000 scale=0.0312 norm=0.0153\n",
      "[iter 215] loss=-0.3126 val_loss=0.0000 scale=0.0312 norm=0.0153\n",
      "[iter 220] loss=-0.3127 val_loss=0.0000 scale=0.0312 norm=0.0153\n",
      "[iter 225] loss=-0.3129 val_loss=0.0000 scale=0.0312 norm=0.0153\n",
      "[iter 230] loss=-0.3130 val_loss=0.0000 scale=0.0312 norm=0.0153\n",
      "[iter 235] loss=-0.3131 val_loss=0.0000 scale=0.0312 norm=0.0153\n",
      "[iter 240] loss=-0.3132 val_loss=0.0000 scale=0.0312 norm=0.0153\n",
      "[iter 245] loss=-0.3133 val_loss=0.0000 scale=0.0312 norm=0.0153\n",
      "[iter 250] loss=-0.3134 val_loss=0.0000 scale=0.0312 norm=0.0153\n",
      "[iter 255] loss=-0.3134 val_loss=0.0000 scale=0.0156 norm=0.0076\n",
      "[iter 260] loss=-0.3135 val_loss=0.0000 scale=0.0156 norm=0.0076\n",
      "[iter 265] loss=-0.3135 val_loss=0.0000 scale=0.0156 norm=0.0076\n",
      "[iter 270] loss=-0.3136 val_loss=0.0000 scale=0.0156 norm=0.0076\n",
      "[iter 275] loss=-0.3136 val_loss=0.0000 scale=0.0156 norm=0.0076\n",
      "[iter 280] loss=-0.3136 val_loss=0.0000 scale=0.0156 norm=0.0076\n",
      "[iter 285] loss=-0.3137 val_loss=0.0000 scale=0.0156 norm=0.0076\n",
      "[iter 290] loss=-0.3137 val_loss=0.0000 scale=0.0156 norm=0.0076\n",
      "[iter 295] loss=-0.3137 val_loss=0.0000 scale=0.0156 norm=0.0076\n",
      "[iter 300] loss=-0.3137 val_loss=0.0000 scale=0.0078 norm=0.0038\n",
      "[iter 305] loss=-0.3137 val_loss=0.0000 scale=0.0078 norm=0.0038\n",
      "[iter 310] loss=-0.3138 val_loss=0.0000 scale=0.0156 norm=0.0076\n",
      "[iter 315] loss=-0.3138 val_loss=0.0000 scale=0.0078 norm=0.0038\n",
      "[iter 320] loss=-0.3138 val_loss=0.0000 scale=0.0078 norm=0.0038\n",
      "[iter 325] loss=-0.3138 val_loss=0.0000 scale=0.0078 norm=0.0038\n",
      "[iter 330] loss=-0.3138 val_loss=0.0000 scale=0.0078 norm=0.0038\n",
      "[iter 335] loss=-0.3138 val_loss=0.0000 scale=0.0078 norm=0.0038\n",
      "[iter 340] loss=-0.3138 val_loss=0.0000 scale=0.0039 norm=0.0019\n",
      "[iter 345] loss=-0.3138 val_loss=0.0000 scale=0.0010 norm=0.0005\n",
      "[iter 350] loss=-0.3138 val_loss=0.0000 scale=0.0078 norm=0.0038\n",
      "[iter 355] loss=-0.3138 val_loss=0.0000 scale=0.0039 norm=0.0019\n",
      "[iter 360] loss=-0.3138 val_loss=0.0000 scale=0.0002 norm=0.0001\n",
      "[iter 365] loss=-0.3138 val_loss=0.0000 scale=0.0039 norm=0.0019\n",
      "[iter 370] loss=-0.3138 val_loss=0.0000 scale=0.0078 norm=0.0038\n",
      "[iter 375] loss=-0.3138 val_loss=0.0000 scale=0.0078 norm=0.0038\n",
      "[iter 380] loss=-0.3138 val_loss=0.0000 scale=0.0020 norm=0.0010\n",
      "[iter 385] loss=-0.3138 val_loss=0.0000 scale=0.0039 norm=0.0019\n",
      "[iter 390] loss=-0.3138 val_loss=0.0000 scale=0.0020 norm=0.0010\n",
      "[iter 395] loss=-0.3138 val_loss=0.0000 scale=0.0078 norm=0.0038\n",
      "[iter 400] loss=-0.3138 val_loss=0.0000 scale=0.0002 norm=0.0001\n",
      "[iter 405] loss=-0.3138 val_loss=0.0000 scale=0.0078 norm=0.0038\n",
      "[iter 410] loss=-0.3138 val_loss=0.0000 scale=0.0039 norm=0.0019\n",
      "[iter 415] loss=-0.3138 val_loss=0.0000 scale=0.0078 norm=0.0038\n",
      "[iter 420] loss=-0.3138 val_loss=0.0000 scale=0.0002 norm=0.0001\n",
      "[iter 425] loss=-0.3138 val_loss=0.0000 scale=0.0002 norm=0.0001\n",
      "[iter 430] loss=-0.3138 val_loss=0.0000 scale=0.0002 norm=0.0001\n",
      "[iter 435] loss=-0.3138 val_loss=0.0000 scale=0.0002 norm=0.0001\n",
      "[iter 440] loss=-0.3138 val_loss=0.0000 scale=0.0039 norm=0.0019\n",
      "[iter 445] loss=-0.3138 val_loss=0.0000 scale=0.0002 norm=0.0001\n",
      "[iter 450] loss=-0.3138 val_loss=0.0000 scale=0.0002 norm=0.0001\n",
      "[iter 455] loss=-0.3138 val_loss=0.0000 scale=0.0020 norm=0.0010\n",
      "[iter 460] loss=-0.3138 val_loss=0.0000 scale=0.0010 norm=0.0005\n",
      "[iter 465] loss=-0.3138 val_loss=0.0000 scale=0.0002 norm=0.0001\n",
      "[iter 470] loss=-0.3139 val_loss=0.0000 scale=0.0039 norm=0.0019\n",
      "[iter 475] loss=-0.3139 val_loss=0.0000 scale=0.0002 norm=0.0001\n",
      "[iter 480] loss=-0.3139 val_loss=0.0000 scale=0.0010 norm=0.0005\n",
      "[iter 485] loss=-0.3139 val_loss=0.0000 scale=0.0020 norm=0.0010\n",
      "[iter 490] loss=-0.3139 val_loss=0.0000 scale=0.0002 norm=0.0001\n",
      "[iter 495] loss=-0.3139 val_loss=0.0000 scale=0.0020 norm=0.0010\n",
      "\n",
      "Test MSE 0.044277893407401146\n",
      "Test NLL -0.21407884954836776\n"
     ]
    }
   ],
   "source": [
    "from ngboost.learners import esn_kernel_ridge_learner\n",
    "model_test(Base=esn_kernel_ridge_learner(n_readout=1000,\n",
    "                                         n_components=100,\n",
    "                                         alpha=1, \n",
    "                                         kernel='poly',\n",
    "                                         degree=3),\n",
    "           X_train=X_train, X_test=X_test,\n",
    "           Y_train=Y_train, Y_test=Y_test,\n",
    "          n_estimators=500, verbose_eval=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## esn_linear_svr_learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-05T10:31:19.295785Z",
     "start_time": "2020-02-05T10:20:57.748488Z"
    },
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NGBRegressor(Base=<ngboost.esn_learners.ESN_linear_svr_learner object at 0x1a1e846e48>,\n",
      "             Dist=<class 'ngboost.distns.normal.Normal'>,\n",
      "             Score=<class 'ngboost.scores.MLE'>, learning_rate=0.01,\n",
      "             minibatch_frac=1.0, n_estimators=500, natural_gradient=True,\n",
      "             tol=0.0001, verbose=True, verbose_eval=10) \n",
      "\n",
      "[iter 0] loss=0.0537 val_loss=0.0000 scale=0.5000 norm=0.2702\n",
      "[iter 10] loss=0.0326 val_loss=0.0000 scale=0.5000 norm=0.2720\n",
      "[iter 20] loss=0.0090 val_loss=0.0000 scale=0.5000 norm=0.2737\n",
      "[iter 30] loss=-0.0174 val_loss=0.0000 scale=0.5000 norm=0.2754\n",
      "[iter 40] loss=-0.0421 val_loss=0.0000 scale=0.5000 norm=0.2789\n",
      "[iter 50] loss=-0.0671 val_loss=0.0000 scale=0.5000 norm=0.2828\n",
      "[iter 60] loss=-0.0858 val_loss=0.0000 scale=0.2500 norm=0.1430\n",
      "[iter 70] loss=-0.0970 val_loss=0.0000 scale=0.2500 norm=0.1442\n",
      "[iter 80] loss=-0.1085 val_loss=0.0000 scale=0.2500 norm=0.1453\n",
      "[iter 90] loss=-0.1192 val_loss=0.0000 scale=0.2500 norm=0.1465\n",
      "[iter 100] loss=-0.1290 val_loss=0.0000 scale=0.2500 norm=0.1476\n",
      "[iter 110] loss=-0.1356 val_loss=0.0000 scale=0.2500 norm=0.1482\n",
      "[iter 120] loss=-0.1408 val_loss=0.0000 scale=0.1250 norm=0.0744\n",
      "[iter 130] loss=-0.1446 val_loss=0.0000 scale=0.1250 norm=0.0746\n",
      "[iter 140] loss=-0.1481 val_loss=0.0000 scale=0.1250 norm=0.0748\n",
      "[iter 150] loss=-0.1512 val_loss=0.0000 scale=0.1250 norm=0.0750\n",
      "[iter 160] loss=-0.1538 val_loss=0.0000 scale=0.1250 norm=0.0751\n",
      "[iter 170] loss=-0.1560 val_loss=0.0000 scale=0.0625 norm=0.0376\n",
      "[iter 180] loss=-0.1573 val_loss=0.0000 scale=0.0625 norm=0.0376\n",
      "[iter 190] loss=-0.1583 val_loss=0.0000 scale=0.0625 norm=0.0377\n",
      "[iter 200] loss=-0.1593 val_loss=0.0000 scale=0.0312 norm=0.0188\n",
      "[iter 210] loss=-0.1600 val_loss=0.0000 scale=0.0312 norm=0.0189\n",
      "[iter 220] loss=-0.1606 val_loss=0.0000 scale=0.0625 norm=0.0377\n",
      "[iter 230] loss=-0.1611 val_loss=0.0000 scale=0.0625 norm=0.0377\n",
      "[iter 240] loss=-0.1616 val_loss=0.0000 scale=0.0312 norm=0.0189\n",
      "[iter 250] loss=-0.1618 val_loss=0.0000 scale=0.0312 norm=0.0189\n",
      "[iter 260] loss=-0.1621 val_loss=0.0000 scale=0.0312 norm=0.0189\n",
      "[iter 270] loss=-0.1623 val_loss=0.0000 scale=0.0156 norm=0.0094\n",
      "[iter 280] loss=-0.1624 val_loss=0.0000 scale=0.0312 norm=0.0189\n",
      "[iter 290] loss=-0.1626 val_loss=0.0000 scale=0.0156 norm=0.0094\n",
      "[iter 300] loss=-0.1627 val_loss=0.0000 scale=0.0312 norm=0.0189\n",
      "[iter 310] loss=-0.1628 val_loss=0.0000 scale=0.0312 norm=0.0189\n",
      "[iter 320] loss=-0.1630 val_loss=0.0000 scale=0.0078 norm=0.0047\n",
      "[iter 330] loss=-0.1631 val_loss=0.0000 scale=0.0078 norm=0.0047\n",
      "[iter 340] loss=-0.1631 val_loss=0.0000 scale=0.0039 norm=0.0024\n",
      "[iter 350] loss=-0.1632 val_loss=0.0000 scale=0.0156 norm=0.0094\n",
      "[iter 360] loss=-0.1632 val_loss=0.0000 scale=0.0156 norm=0.0094\n",
      "[iter 370] loss=-0.1632 val_loss=0.0000 scale=0.0156 norm=0.0094\n",
      "[iter 380] loss=-0.1633 val_loss=0.0000 scale=0.0156 norm=0.0094\n",
      "[iter 390] loss=-0.1633 val_loss=0.0000 scale=0.0001 norm=0.0001\n",
      "[iter 400] loss=-0.1633 val_loss=0.0000 scale=0.0156 norm=0.0094\n",
      "[iter 410] loss=-0.1634 val_loss=0.0000 scale=0.0001 norm=0.0001\n",
      "[iter 420] loss=-0.1634 val_loss=0.0000 scale=0.0039 norm=0.0024\n",
      "[iter 430] loss=-0.1634 val_loss=0.0000 scale=0.0078 norm=0.0047\n",
      "[iter 440] loss=-0.1634 val_loss=0.0000 scale=0.0039 norm=0.0024\n",
      "[iter 450] loss=-0.1635 val_loss=0.0000 scale=0.0001 norm=0.0001\n",
      "[iter 460] loss=-0.1635 val_loss=0.0000 scale=0.0001 norm=0.0001\n",
      "[iter 470] loss=-0.1635 val_loss=0.0000 scale=0.0039 norm=0.0024\n",
      "[iter 480] loss=-0.1635 val_loss=0.0000 scale=0.0156 norm=0.0094\n",
      "[iter 490] loss=-0.1635 val_loss=0.0000 scale=0.0001 norm=0.0001\n",
      "\n",
      "Test MSE 0.027501347070637904\n",
      "Test NLL -0.32032451782817833\n"
     ]
    }
   ],
   "source": [
    "from ngboost.learners import esn_linear_svr_learner\n",
    "model_test(Base=esn_linear_svr_learner(n_readout=1000,\n",
    "                                         n_components=100,\n",
    "                                         epsilon=0.0,\n",
    "                                         C=0.02,\n",
    "                                         max_iter=1000),\n",
    "           X_train=X_train, X_test=X_test,\n",
    "           Y_train=Y_train, Y_test=Y_test,\n",
    "          n_estimators=500, verbose_eval=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "notify_time": "0",
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "222.60870361328125px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
